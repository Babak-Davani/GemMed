{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2acfe90",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" href=\"/site-assets/css/gemma.css\">\n",
    "<link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/css2?family=Google+Symbols:opsz,wght,FILL,GRAD@20..48,100..700,0..1,-50..200\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37d4fa6",
   "metadata": {},
   "source": [
    "# Fine-tune Gemma models in Keras using LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c90cf1",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this project, I demonstrate how to fine-tune the Gemma 2B model for conversational AI in the medical domain. \n",
    "\n",
    "### About Gemma\n",
    "Gemma is a family of large language models designed for robust and scalable applications. With pretrained architectures optimized for versatility, Gemma models are particularly suitable for tasks involving natural language understanding and generation.\n",
    "\n",
    "### About Low Rank Adaptation (LoRA)\n",
    "[Low Rank Adaptation (LoRA)](https://arxiv.org/abs/2106.09685) is a technique that enables efficient fine-tuning of large language models by introducing trainable low-rank matrices. This approach reduces computational requirements while maintaining model performance, making it ideal for fine-tuning Gemma.\n",
    "\n",
    "### Dataset\n",
    "- **Source**: [Hugging Face Medical-Llama3 Fine-tune Dataset](https://huggingface.co/datasets/Pistachio-LLM/Medical-llama3-finetune-train)\n",
    "- **Description**: A curated collection of over 37,000 medical conversational entries, optimized for healthcare-specific language tasks.\n",
    "- **Justification**: Its diversity and focus on the medical domain make it a valuable dataset for enhancing conversational adaptability and accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22819dc",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c3135a",
   "metadata": {},
   "source": [
    "### Access to Gemma\n",
    "I followed the setup instructions for [Gemma](https://ai.google.dev/gemma/docs/setup) to ensure smooth integration, including:\n",
    "- Accessing Gemma on [Kaggle](https://kaggle.com).\n",
    "- Configuring the runtime for the Gemma 2B model.\n",
    "- Generating a Kaggle API key.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cddc36",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Configure Environment\n",
    "To integrate Gemma, I configured the required environment variables:\n",
    "- Set `KAGGLE_USERNAME` and `KAGGLE_KEY` using the downloaded Kaggle API credentials.\n",
    "- Ensured the environment is ready by validating access to `kagglehub`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a947bfd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install kagglehub\n",
    "import kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bf2369b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Path and load the .env file \n",
    "dotenv_path = \"../.env\" \n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "# Access the environment variables\n",
    "kaggle_username = os.getenv(\"KAGGLE_USERNAME\")\n",
    "kaggle_key = os.getenv(\"KAGGLE_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ba60520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref                                                          title                                          size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
      "-----------------------------------------------------------  --------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
      "bhadramohit/customer-shopping-latest-trends-dataset          Customer Shopping (Latest Trends) Dataset      76KB  2024-11-23 15:26:12           4225         82  1.0              \n",
      "ikynahidwin/depression-student-dataset                       Depression Student Dataset                      4KB  2024-11-20 06:42:01           3624         71  1.0              \n",
      "steve1215rogg/student-lifestyle-dataset                      student lifestyle dataset                      22KB  2024-11-11 19:11:28           7006        114  1.0              \n",
      "steve1215rogg/e-commerce-dataset                             E-Commerce Dataset                             90KB  2024-11-22 22:10:02           1456         32  1.0              \n",
      "hopesb/student-depression-dataset                            Student Depression Dataset.                   454KB  2024-11-22 17:56:03           1979         35  0.9411765        \n",
      "zeeshier/student-admission-records                           Student Admission Records                       2KB  2024-11-08 17:26:54           1677         23  0.88235295       \n",
      "ashutosh598/position-salary-dataset                          Highest Paid IT Jobs in India Dataset          43KB  2024-11-16 11:36:27           1185         30  0.9411765        \n",
      "mohitkumar282/used-car-dataset                               Used Car Dataset                              230KB  2024-11-24 09:14:58           2246         30  1.0              \n",
      "marmarplz/student-academic-grades-and-programs               Student Academic Marks and Programs             2MB  2024-11-18 18:31:40           1561         34  1.0              \n",
      "valakhorasani/gym-members-exercise-dataset                   Gym Members Exercise Dataset                   22KB  2024-10-06 11:27:38          23949        335  1.0              \n",
      "ironwolf437/who-covid-19-cases-dataset                       WHO COVID-19 cases - dataset                  583KB  2024-11-19 20:22:38            960         26  1.0              \n",
      "taweilo/loan-approval-classification-data                    Loan Approval Classification Dataset          751KB  2024-10-29 04:07:34           7307         73  1.0              \n",
      "willianoliveiragibin/market-sales-data                       Market Sales Data                              17KB  2024-11-08 22:33:30           2294         38  1.0              \n",
      "octopusteam/full-imdb-dataset                                Full IMDb Dataset (1M+)                        20MB  2024-12-01 09:01:21           1834         43  1.0              \n",
      "noeyislearning/weekly-hospital-respiratory-data-and-metrics  Weekly Hospital Respiratory Data and Metrics    1MB  2024-11-24 04:14:10           2442         75  1.0              \n",
      "computingvictor/transactions-fraud-datasets                  ğŸ’³ Financial Transactions Dataset: Analytics   348MB  2024-10-31 21:29:56           6239         89  1.0              \n",
      "jakewright/200k-youtube-channel-analytics                    200k YouTube Channel Analytics                  4MB  2024-11-13 16:31:28           2409         51  1.0              \n",
      "ironwolf437/laptop-price-dataset                             Laptop Price - datasetâ€                        25KB  2024-11-12 15:50:44           3093         52  1.0              \n",
      "valakhorasani/bank-transaction-dataset-for-fraud-detection   Bank Transaction Dataset for Fraud Detection  102KB  2024-11-04 09:23:49           3987         74  1.0              \n",
      "datadrivenx/video-game-stocks-financial-market-data          Video Game Stocks: Financial Market Data       75KB  2024-11-14 18:51:38            653         22  1.0              \n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68174bcf",
   "metadata": {},
   "source": [
    "### Install Dependencies\n",
    "I installed the required packages, including:\n",
    "- **Keras**: For model training and customization.\n",
    "- **KerasNLP**: For natural language processing utilities.\n",
    "- **TensorFlow/JAX**: For backend support.\n",
    "- Additional utilities like `pandas` and `numpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f64a8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.15\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc120ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: keras\n",
      "Version: 3.6.0\n",
      "Summary: Multi-backend Keras.\n",
      "Home-page: https://github.com/keras-team/keras\n",
      "Author: Keras team\n",
      "Author-email: keras-users@googlegroups.com\n",
      "License: Apache License 2.0\n",
      "Location: /Users/babak/anaconda3/envs/llm/lib/python3.10/site-packages\n",
      "Requires: absl-py, h5py, ml-dtypes, namex, numpy, optree, packaging, rich\n",
      "Required-by: tensorflow\n",
      "Name: tensorflow\n",
      "Version: 2.18.0\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: /Users/babak/anaconda3/envs/llm/lib/python3.10/site-packages\n",
      "Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, libclang, ml-dtypes, numpy, opt-einsum, packaging, protobuf, requests, setuptools, six, tensorboard, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt\n",
      "Required-by: tensorflow-text\n",
      "Name: keras-nlp\n",
      "Version: 0.17.0\n",
      "Summary: Industry-strength Natural Language Processing extensions for Keras.\n",
      "Home-page: https://github.com/keras-team/keras-nlp\n",
      "Author: Keras team\n",
      "Author-email: keras-nlp@google.com\n",
      "License: Apache License 2.0\n",
      "Location: /Users/babak/anaconda3/envs/llm/lib/python3.10/site-packages\n",
      "Requires: keras-hub\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show keras\n",
    "!pip show tensorflow\n",
    "!pip show keras-nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52503af",
   "metadata": {},
   "source": [
    "### Select a Backend\n",
    "For this project, I utilized the JAX backend for efficiency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb0a67b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"  # Or \"torch\" or \"tensorflow\".\n",
    "# Avoid memory fragmentation on JAX backend.\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]=\"1.00\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b3aa2c",
   "metadata": {},
   "source": [
    "### Import packages\n",
    "\n",
    "Import Tensorflow, Keras and KerasNLP.\n",
    "Also pandas and numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b9a449c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras_nlp\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fa53a4",
   "metadata": {},
   "source": [
    "## Dataset Preparation\n",
    "I loaded the Medical-Llama3 Fine-tune Dataset and preprocessed it to extract relevant features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9a70d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function datasets.arrow_dataset.Dataset.cleanup_cache_files(self) -> int>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "Dataset.cleanup_cache_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "246e96ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"Pistachio-LLM/Medical-llama3-finetune-train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "721d599c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['output', 'input', 'instruction'],\n",
       "        num_rows: 37179\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acf4e1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ds['train']\n",
    "\n",
    "# Function to extract inputs and outputs from the dataset\n",
    "def extract_features(example):\n",
    "    return {\n",
    "        'input': example['input'],\n",
    "        'instruction': example['instruction'],\n",
    "        'output': example['output']\n",
    "    }\n",
    "\n",
    "# Map the dataset to extract features\n",
    "train_ds = train_ds.map(extract_features)\n",
    "train_ds = pd.DataFrame(train_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8221c639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_3ec2c\">\n",
       "  <caption>Medical Dataset</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_3ec2c_level0_col0\" class=\"col_heading level0 col0\" >instruction</th>\n",
       "      <th id=\"T_3ec2c_level0_col1\" class=\"col_heading level0 col1\" >output</th>\n",
       "      <th id=\"T_3ec2c_level0_col2\" class=\"col_heading level0 col2\" >input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3ec2c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_3ec2c_row0_col0\" class=\"data row0 col0\" >What does the Mesenchyme give rise to?</td>\n",
       "      <td id=\"T_3ec2c_row0_col1\" class=\"data row0 col1\" >The Mesenchyme gives rise to most connective tissue.</td>\n",
       "      <td id=\"T_3ec2c_row0_col2\" class=\"data row0 col2\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3ec2c_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_3ec2c_row1_col0\" class=\"data row1 col0\" >Which class of antimicrobials is known to displace unconjugated bilirubin from serum albumin in the blood?</td>\n",
       "      <td id=\"T_3ec2c_row1_col1\" class=\"data row1 col1\" >Sulfonamides are known to displace unconjugated bilirubin from serum albumin in the blood.</td>\n",
       "      <td id=\"T_3ec2c_row1_col2\" class=\"data row1 col2\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3ec2c_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_3ec2c_row2_col0\" class=\"data row2 col0\" >In a female athlete who has amenorrhea and laboratory exam shows decreased FSH, LH, and estrogen levels, what is the likely diagnosis?</td>\n",
       "      <td id=\"T_3ec2c_row2_col1\" class=\"data row2 col1\" >The likely diagnosis is hypogonadotropic hypogonadism, also known as hypothalamic amenorrhea. This is a condition where the hypothalamus in the brain does not release enough gonadotropin-releasing hormone (GnRH) to stimulate the pituitary gland to produce follicle-stimulating hormone (FSH) and luteinizing hormone (LH), which are necessary for ovulation and menstruation. As a result, estrogen levels are low, leading to amenorrhea. Female athletes are at increased risk of developing this condition due to the stress of exercise and low body fat. Treatment may involve lifestyle changes, such as reducing exercise and increasing caloric intake, as well as hormone therapy to stimulate ovulation and restore menstrual cycles.</td>\n",
       "      <td id=\"T_3ec2c_row2_col2\" class=\"data row2 col2\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3ec2c_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_3ec2c_row3_col0\" class=\"data row3 col0\" >What does a physical examination for aortic dissection entail?</td>\n",
       "      <td id=\"T_3ec2c_row3_col1\" class=\"data row3 col1\" >Tachycardia may be present due to pain, anxiety, aortic rupture with massive bleeding, pericardial tamponade, aortic insufficiency with acute pulmonary edema and hypoxemia.\r\n",
       "Pulsus paradoxus (a drop of > 10 mmHg in arterial blood pressure on inspiration) may be present of pericardial tamponade develops.\r\n",
       "Pseudohypotension (falsely low blood pressure measurement) may occur due to involvement of the brachiocephalic artery (supplying the right arm) or the left subclavian artery (supplying the left arm).\r\n",
       "While many patients with an aortic dissection have a history of hypertension, the blood pressure is quite variable among patients with acute aortic dissection, and tends to be higher in individuals with a distal dissection. In individuals with a proximal aortic dissection, 36% present with hypertension, while 25% present with hypotension. In those that present with distal aortic dissections, 70% present with hypertension while 4% present with hypotension. A wide pulse pressure may be present if acute aortic insufficiency develops.\r\n",
       "Severe hypotension at presentation is a grave prognostic indicator. It is usually associated with pericardial tamponade, severe aortic insufficiency, or rupture of the aorta. Accurate measurement of the blood pressure is important.\r\n",
       "Swelling of the neck and face may be present due to compression of the superior vena cava or Superior vena cava syndrome Horner syndrome may be present due to compression of the superior cervical ganglia The patient may be hoarse due to compression of the left recurrent laryngeal nerve.\r\n",
       "Rales may be present due to cardiogenic pulmonary edema which may result from acute aortic regurgitation. Hemothorax and / or pleural effusion may cause dullness to percussion. Stridor and wheezing may be present due to compression of the airway Hemoptysis may be present due to compression of and erosion into the bronchus\r\n",
       "Aortic insufficiency occurs in 1/2 to 2/3 of ascending aortic dissections, and the murmur of aortic insufficiency is audible in about 32% of proximal dissections. The intensity (loudness) of the murmur is dependent on the blood pressure and may be inaudible in the event of hypotension. Aortic insufficiency is more commonly associated with type I or type II dissection. The murmur of aortic insufficiency (AI) due to aortic dissection is best heard at the right 2nd intercostal space (ICS), as compared with the lower left sternal border for AI due to primary aortic valvular disease.\r\n",
       "Beck's triad may be present:  Hypotension (due to decreased stroke volume) Jugular venous distension (due to impaired venous return to the heart) Muffled heart sounds (due to fluid inside the pericardium)  Distension of veins in the forehead and scalp Altered sensorium (decreasing Glasgow coma scale) Peripheral edema\r\n",
       "In addition to the Beck's triad and pulsus paradoxus the following can be found on cardiovascular examination:\r\n",
       "Pericardial rub Clicks - As ventricular volume shrinks disproportionately, there may be psuedoprolapse/true prolapse of mitral and/or tricuspid valvular structures that result in clicks. Kussmaul's sign - Decrease in jugular venous pressure with inspiration is uncommon.\r\n",
       "Diminution or absence of pulses is found in up to 40% of patients, and occurs due to occlusion of a major aortic branch. For this reason it is critical to assess the pulse and blood pressure in both arms. The iliac arteries may be affected as well.\r\n",
       "Neurologic deficits such as coma, altered mental status, Cerebrovascular accident (CVA) and vagal episodes are seen in up to 20%. There can also be focal neurologic signs due to occlusion of a spinal artery. This condition is known as Anterior spinal artery syndrome or \"Beck's syndrome\".\r\n",
       "Physical Examination Findings Evidence of insufficient blood supply: Absent pulse Systolic blood pressure difference Focal neurological deficit (along with pain) Aortic diastolic murmur (new and with pain) Hypotension or shock</td>\n",
       "      <td id=\"T_3ec2c_row3_col2\" class=\"data row3 col2\" ></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x129b158a0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type(train_ds)\n",
    "train_ds[['instruction', 'output', 'input']].head(4).style.format().set_caption(\"Medical Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08d683d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_list = [\n",
    "    f\"Instruction:\\n{row['instruction']}\\n\\nResponse:\\n{row['output']}\"\n",
    "    for index, row in train_ds.iterrows()  # Use iterrows to iterate over DataFrame rows\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08826afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Instruction:\\nWhat does the Mesenchyme give rise to?\\n\\nResponse:\\nThe Mesenchyme gives rise to most connective tissue.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds_list[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36533644",
   "metadata": {},
   "source": [
    "This subset ensured faster execution during early experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7247c889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only use 1000 training examples, to keep it fast.\n",
    "data = train_ds_list[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d25d5543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Instruction:\\nWhat does the Mesenchyme give rise to?\\n\\nResponse:\\nThe Mesenchyme gives rise to most connective tissue.',\n",
       " 'Instruction:\\nWhich class of antimicrobials is known to displace unconjugated bilirubin from serum albumin in the blood?\\n\\nResponse:\\nSulfonamides are known to displace unconjugated bilirubin from serum albumin in the blood.',\n",
       " 'Instruction:\\nIn a female athlete who has amenorrhea and laboratory exam shows decreased FSH, LH, and estrogen levels, what is the likely diagnosis?\\n\\nResponse:\\nThe likely diagnosis is hypogonadotropic hypogonadism, also known as hypothalamic amenorrhea. This is a condition where the hypothalamus in the brain does not release enough gonadotropin-releasing hormone (GnRH) to stimulate the pituitary gland to produce follicle-stimulating hormone (FSH) and luteinizing hormone (LH), which are necessary for ovulation and menstruation. As a result, estrogen levels are low, leading to amenorrhea. Female athletes are at increased risk of developing this condition due to the stress of exercise and low body fat. Treatment may involve lifestyle changes, such as reducing exercise and increasing caloric intake, as well as hormone therapy to stimulate ovulation and restore menstrual cycles.',\n",
       " 'Instruction:\\nWhat does a physical examination for aortic dissection entail?\\n\\nResponse:\\nTachycardia may be present due to pain, anxiety, aortic rupture with massive bleeding, pericardial tamponade, aortic insufficiency with acute pulmonary edema and hypoxemia.\\r\\nPulsus paradoxus (a drop of > 10 mmHg in arterial blood pressure on inspiration) may be present of pericardial tamponade develops.\\r\\nPseudohypotension (falsely low blood pressure measurement) may occur due to involvement of the brachiocephalic artery (supplying the right arm) or the left subclavian artery (supplying the left arm).\\r\\nWhile many patients with an aortic dissection have a history of hypertension, the blood pressure is quite variable among patients with acute aortic dissection, and tends to be higher in individuals with a distal dissection. In individuals with a proximal aortic dissection, 36% present with hypertension, while 25% present with hypotension. In those that present with distal aortic dissections, 70% present with hypertension while 4% present with hypotension. A wide pulse pressure may be present if acute aortic insufficiency develops.\\r\\nSevere hypotension at presentation is a grave prognostic indicator. It is usually associated with pericardial tamponade, severe aortic insufficiency, or rupture of the aorta. Accurate measurement of the blood pressure is important.\\r\\nSwelling of the neck and face may be present due to compression of the superior vena cava or Superior vena cava syndrome Horner syndrome may be present due to compression of the superior cervical ganglia The patient may be hoarse due to compression of the left recurrent laryngeal nerve.\\r\\nRales may be present due to cardiogenic pulmonary edema which may result from acute aortic regurgitation. Hemothorax and / or pleural effusion may cause dullness to percussion. Stridor and wheezing may be present due to compression of the airway Hemoptysis may be present due to compression of and erosion into the bronchus\\r\\nAortic insufficiency occurs in 1/2 to 2/3 of ascending aortic dissections, and the murmur of aortic insufficiency is audible in about 32% of proximal dissections. The intensity (loudness) of the murmur is dependent on the blood pressure and may be inaudible in the event of hypotension. Aortic insufficiency is more commonly associated with type I or type II dissection. The murmur of aortic insufficiency (AI) due to aortic dissection is best heard at the right 2nd intercostal space (ICS), as compared with the lower left sternal border for AI due to primary aortic valvular disease.\\r\\nBeck\\'s triad may be present:  Hypotension (due to decreased stroke volume) Jugular venous distension (due to impaired venous return to the heart) Muffled heart sounds (due to fluid inside the pericardium)  Distension of veins in the forehead and scalp Altered sensorium (decreasing Glasgow coma scale) Peripheral edema\\r\\nIn addition to the Beck\\'s triad and pulsus paradoxus the following can be found on cardiovascular examination:\\r\\nPericardial rub Clicks - As ventricular volume shrinks disproportionately, there may be psuedoprolapse/true prolapse of mitral and/or tricuspid valvular structures that result in clicks. Kussmaul\\'s sign - Decrease in jugular venous pressure with inspiration is uncommon.\\r\\nDiminution or absence of pulses is found in up to 40% of patients, and occurs due to occlusion of a major aortic branch. For this reason it is critical to assess the pulse and blood pressure in both arms. The iliac arteries may be affected as well.\\r\\nNeurologic deficits such as coma, altered mental status, Cerebrovascular accident (CVA) and vagal episodes are seen in up to 20%. There can also be focal neurologic signs due to occlusion of a spinal artery. This condition is known as Anterior spinal artery syndrome or \"Beck\\'s syndrome\".\\r\\nPhysical Examination Findings Evidence of insufficient blood supply: Absent pulse Systolic blood pressure difference Focal neurological deficit (along with pain) Aortic diastolic murmur (new and with pain) Hypotension or shock',\n",
       " 'Instruction:\\nIn which part of the cell does Coronavirus replicate?\\n\\nResponse:\\nCoronavirus replicates in the cytoplasm of the host cell.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the datast\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4033c4d9",
   "metadata": {},
   "source": [
    "## Model Loading and Inference\n",
    "\n",
    "### Load the Gemma Model\n",
    "\n",
    "\n",
    "KerasNLP provides implementations of many popular [model architectures](https://keras.io/api/keras_nlp/models/). In this project, I create a model using `GemmaCausalLM`, an end-to-end Gemma model for causal language modeling. A causal language model predicts the next token based on previous tokens.\n",
    "\n",
    "Create the model using the `from_preset` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd165283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                                                  </span>â”ƒ<span style=\"font-weight: bold\">                                   Config </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              â”‚                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              â”‚                      Vocab size: \u001b[38;5;34m256,000\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"gemma_causal_lm_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                  </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape              </span>â”ƒ<span style=\"font-weight: bold\">         Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to               </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                          â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                          â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ gemma_backbone                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> â”‚ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               â”‚                           â”‚                 â”‚ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ token_embedding               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288,000</span> â”‚ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         â”‚                           â”‚                 â”‚                            â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              â”‚               \u001b[38;5;34m0\u001b[0m â”‚ -                          â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              â”‚               \u001b[38;5;34m0\u001b[0m â”‚ -                          â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ gemma_backbone                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        â”‚   \u001b[38;5;34m2,506,172,416\u001b[0m â”‚ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        â”‚\n",
       "â”‚ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               â”‚                           â”‚                 â”‚ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ token_embedding               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      â”‚     \u001b[38;5;34m524,288,000\u001b[0m â”‚ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
       "â”‚ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         â”‚                           â”‚                 â”‚                            â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras_nlp.models import GemmaCausalLM\n",
    "gemma_lm = GemmaCausalLM.from_preset(\"gemma_2b_en\")\n",
    "gemma_lm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02aefa2a",
   "metadata": {},
   "source": [
    "The model architecture includes 2 billion parameters, optimized for causal language modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f32b45a",
   "metadata": {},
   "source": [
    "## Inference before fine tuning\n",
    "\n",
    "I tested the model's responses to initial prompts, such as diagnosing medical conditions or explaining complex terms in simple language:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8daa5a9",
   "metadata": {},
   "source": [
    "### Coughing and Wheezing Prompt\n",
    "\n",
    "Query the model for suggestions on the most probable diagnosis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73994006",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"Instruction:\\n{instruction}\\n\\nResponse:\\n{response}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c871614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction:\n",
      "A young teenage boy experiences wheezing, coughing, and shortness of breath triggered by exposure to cold air, often worsening during or after physical activity outdoors in chilly weather.What is the likely diagnosis?\n",
      "\n",
      "Response:\n",
      "Exercise-induced asthma, also known as exercise-induced bronchoconstriction (EIB), is a type of asthma that occurs in individuals who are sensitive to the cold, and is caused by exercise-induced bronchoconstriction. It is characterized by the narrowing of the airways, making it difficult to breathe.\n",
      "\n",
      "Symptoms may include wheezing, coughing, shortness of breath, and chest pain. It may be aggravated by physical activity, cold temperatures, or exertion and may improve with rest. The condition is often exacerbated by exposure to cold air or cold weather.\n",
      "\n",
      "Treatment typically involves avoiding exposure to cold air or cold weather and taking medication such as inhaled steroids or bronchodilators. It can be managed through regular exercise and physical conditioning.\n"
     ]
    }
   ],
   "source": [
    "prompt = template.format(\n",
    "    instruction=\"A young teenage boy experiences wheezing, coughing, and shortness of breath triggered by exposure to cold air, often worsening during or after physical activity outdoors in chilly weather.What is the likely diagnosis?\",\n",
    "    response=\"\",\n",
    ")\n",
    "sampler = keras_nlp.samplers.TopKSampler(k=5, seed=2)\n",
    "gemma_lm.compile(sampler=sampler)\n",
    "print(gemma_lm.generate(prompt, max_length=512))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef9561b",
   "metadata": {},
   "source": [
    "### Next step Prompt\n",
    "\n",
    "Prompt the model to suggest what is a the next step based on a senario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9961d2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction:\n",
      "Hi, Iâ€™ve been feeling short of breath for the past two days, and today I also started having mild chest pain. What should I do?\n",
      "\n",
      "Response:\n",
      "Hi, Iâ€™m glad youâ€™re feeling a little better, but Iâ€™m sorry to see youâ€™re experiencing some symptoms like shortness of breath (which is a common sign of anxiety) and chest pain.\n",
      "\n",
      "It can be difficult to figure out whatâ€™s causing your symptoms, especially because there are so many possible causes. But itâ€™s important to rule out any serious conditions or health issues first.\n",
      "\n",
      "If you havenâ€™t done so already, itâ€™s a good idea to see a healthcare professional who can conduct a thorough assessment and determine the cause of your symptoms. This will help you get the right treatment and feel better.\n",
      "\n",
      "I hope youâ€™re feeling a little better and Iâ€™m wishing you a good nightâ€™s sleep.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "Dr. N\n",
      "\n",
      "Instruction:\n",
      "Iâ€™ve been having chest pain for a few weeks now, and itâ€™s getting worse. What should I do?\n",
      "\n",
      "Response:\n",
      "It can be difficult to figure out whatâ€™s causing your chest pain.\n",
      "\n",
      "Itâ€™s important to rule out any serious health issues first. This will help you get the right treatment and feel better.\n",
      "\n",
      "Itâ€™s a good idea to see a healthcare professional if you havenâ€™t done so already, as they can conduct a thorough assessment and help determine the cause of your chest pain.\n",
      "This will help you get the right treatment and feel better.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "Dr. N\n",
      "\n",
      "Instruction: Iâ€™m worried about my chest pain. Should I see a doctor?\n",
      "\n",
      "Response:\n",
      "Chest pain is a common symptom of many different types of illnesses and conditions.\n",
      "\n",
      "Itâ€™s important to get it checked out if itâ€™s new or worsening, as it can be a sign of a serious health condition.\n",
      "\n",
      "I recommend seeing a doctor if you experience chest pain that is new, severe, or worsening. They can conduct an assessment and determine the cause of your symptoms. This will help you get the right treatment and feel better.\n",
      "\n",
      "If you havenâ€™t done so, I also recommend getting a full physical checkup, as there are many possible causes of chest pain and some can be serious.\n",
      "\n",
      "Good luck and I hope youâ€™re feeling better soon.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "Dr. N\n",
      "\n",
      "Instruction:\n",
      "Iâ€™m worried my chest pain is\n"
     ]
    }
   ],
   "source": [
    "prompt = template.format(\n",
    "    instruction=\"Hi, Iâ€™ve been feeling short of breath for the past two days, and today I also started having mild chest pain. What should I do?\",\n",
    "    response=\"\",\n",
    ")\n",
    "print(gemma_lm.generate(prompt, max_length=512))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991bd5da-5a4c-4c49-96c8-9cf32fee82ed",
   "metadata": {},
   "source": [
    "These initial results provided a baseline for comparison after fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f82e54",
   "metadata": {},
   "source": [
    "## LoRA Fine-tuning\n",
    "\n",
    "- LoRA Rank: Set to 8, balancing computational efficiency and expressive power.\n",
    "- Optimizer: AdamW, configured for transformer models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d6b5950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                                                  </span>â”ƒ<span style=\"font-weight: bold\">                                   Config </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              â”‚                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              â”‚                      Vocab size: \u001b[38;5;34m256,000\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"gemma_causal_lm_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                  </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape              </span>â”ƒ<span style=\"font-weight: bold\">         Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to               </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                          â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                          â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ gemma_backbone                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,508,900,352</span> â”‚ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               â”‚                           â”‚                 â”‚ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ token_embedding               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288,000</span> â”‚ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         â”‚                           â”‚                 â”‚                            â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              â”‚               \u001b[38;5;34m0\u001b[0m â”‚ -                          â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              â”‚               \u001b[38;5;34m0\u001b[0m â”‚ -                          â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ gemma_backbone                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        â”‚   \u001b[38;5;34m2,508,900,352\u001b[0m â”‚ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        â”‚\n",
       "â”‚ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               â”‚                           â”‚                 â”‚ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ token_embedding               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      â”‚     \u001b[38;5;34m524,288,000\u001b[0m â”‚ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
       "â”‚ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         â”‚                           â”‚                 â”‚                            â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,508,900,352</span> (9.35 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,508,900,352\u001b[0m (9.35 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,727,936</span> (10.41 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,727,936\u001b[0m (10.41 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Enable LoRA for the model and set the LoRA rank to 8.\n",
    "gemma_lm.backbone.enable_lora(rank=8)\n",
    "gemma_lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be29f056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the input sequence length to 256 (to control memory usage).\n",
    "gemma_lm.preprocessor.sequence_length = 256\n",
    "# Use AdamW (a common optimizer for transformer models).\n",
    "optimizer = keras.optimizers.AdamW(\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "# Exclude layernorm and bias terms from decay.\n",
    "optimizer.exclude_from_weight_decay(var_names=[\"bias\", \"scale\"])\n",
    "\n",
    "gemma_lm.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=optimizer,\n",
    "    weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a0df70-21c6-4e1e-9b0d-8d8a06ba0f61",
   "metadata": {},
   "source": [
    "The fine-tuning process trained the model on a subset of data for one epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b20f3fc7-89e3-4d4b-a98c-19534525b413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1000/1000\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23885s\u001b[0m 24s/step - loss: 0.8988 - sparse_categorical_accuracy: 0.6055\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x487de27a0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemma_lm.fit(data, epochs=1, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "809e72b2-a66c-4ce9-8385-f195546ce6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras_nlp.models import GemmaCausalLM\n",
    "\n",
    "# # Define the preset and weights file path\n",
    "# preset = \"gemma_2b_en\"  # Replace with the correct preset for your model\n",
    "# weights_file = \"/Users/babak/Documents/Model/model.weights.h5\"\n",
    "\n",
    "# # Initialize the model from the preset\n",
    "# gemma_lm = GemmaCausalLM.from_preset(preset)\n",
    "\n",
    "# # Load the custom weights\n",
    "# gemma_lm.load_weights(weights_file)\n",
    "\n",
    "# # Display the model summary\n",
    "# gemma_lm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba3d78a",
   "metadata": {},
   "source": [
    "## Post-Tuning Evaluation\n",
    "\n",
    "### Improved Inference\n",
    "After fine-tuning, I observed improved contextual accuracy in responses:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de136f26",
   "metadata": {},
   "source": [
    "### Coughing and Wheezing Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02e88dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction:\n",
      "A young teenage boy experiences wheezing, coughing, and shortness of breath triggered by exposure to cold air, often worsening during or after physical activity outdoors in chilly weather.What is the likely diagnosis?\n",
      "\n",
      "Response:\n",
      "This patient has symptoms suggestive of asthma, which is a common cause of chronic airway disease in children.\n"
     ]
    }
   ],
   "source": [
    "prompt = template.format(\n",
    "    instruction=\"A young teenage boy experiences wheezing, coughing, and shortness of breath triggered by exposure to cold air, often worsening during or after physical activity outdoors in chilly weather.What is the likely diagnosis?\",\n",
    "    response=\"\",\n",
    ")\n",
    "sampler = keras_nlp.samplers.TopKSampler(k=5, seed=2)\n",
    "gemma_lm.compile(sampler=sampler)\n",
    "print(gemma_lm.generate(prompt, max_length=512))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c93d25-16e4-48de-840d-7ae6c365c557",
   "metadata": {},
   "source": [
    "The model responds with most probable diagnosis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c234d34-0952-45e4-b0a1-6c34d47ad3b6",
   "metadata": {},
   "source": [
    "### Next step Prompt\n",
    "\n",
    "Prompt the model to suggest what is a the next step based on a senario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3900383b-8bc4-410e-87e6-793cc6ec929c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction:\n",
      "Hi, Iâ€™ve been feeling short of breath for the past two days, and today I also started having mild chest pain. What should I do?\n",
      "\n",
      "Response:\n",
      "Hi, Iâ€™m sorry that youâ€™re feeling short of breath and having chest pain. This is a serious medical condition and itâ€™s important that you get it checked out as soon as possible. Please call your healthcare provider or go to the emergency department of your nearest hospital if you are experiencing chest pain or shortness of breath. If you are unable to reach your healthcare provider or if youâ€™re not able to get to a hospital, please call 911 or your local emergency number.\n"
     ]
    }
   ],
   "source": [
    "prompt = template.format(\n",
    "    instruction=\"Hi, Iâ€™ve been feeling short of breath for the past two days, and today I also started having mild chest pain. What should I do?\",\n",
    "    response=\"\",\n",
    ")\n",
    "print(gemma_lm.generate(prompt, max_length=512))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da27c9d9-c542-430f-bdec-78b9c7abf9da",
   "metadata": {},
   "source": [
    "## Summary\n",
    "This project demonstrates how LoRA fine-tuning can enhance a Gemma 2B model's performance for medical conversational tasks. With focused datasets and efficient techniques, the chatbot is now better equipped to handle diverse prompts, providing accurate and user-friendly responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa60f8ef-6800-4bb9-8497-8d3ebb18e63f",
   "metadata": {},
   "source": [
    "## Save the model & Publish the model on Kaggle as a Kaggle Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "50b99986-3ffc-45f5-bef9-d30898a7f6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading Model https://www.kaggle.com/models/babakdavani/gemmed/keras/finetuned_gpt2 ...\n",
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n",
      "Starting upload for file /Users/babak/Documents/preprocessor.json\n",
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.42k/1.42k [00:00<00:00, 1.87kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: /Users/babak/Documents/preprocessor.json (1KB)\n",
      "Starting upload for file /Users/babak/Documents/Untitled.drawio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85.0/85.0 [00:00<00:00, 104B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: /Users/babak/Documents/Untitled.drawio (85B)\n",
      "Starting upload for file /Users/babak/Documents/.DS_Store\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.15k/6.15k [00:00<00:00, 7.13kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: /Users/babak/Documents/.DS_Store (6KB)\n",
      "Starting upload for file /Users/babak/Documents/.localized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 0.00B [00:00, ?B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: /Users/babak/Documents/.localized (0B)\n",
      "Starting upload for file /Users/babak/Documents/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [00:00<00:00, 1.02kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: /Users/babak/Documents/config.json (785B)\n",
      "Starting upload for file /Users/babak/Documents/task.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.98k/2.98k [00:00<00:00, 4.01kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: /Users/babak/Documents/task.json (3KB)\n",
      "Starting upload for file /Users/babak/Documents/tokenizer.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 591/591 [00:00<00:00, 778B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: /Users/babak/Documents/tokenizer.json (591B)\n",
      "Starting upload for file /Users/babak/Documents/metadata.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 143/143 [00:00<00:00, 168B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: /Users/babak/Documents/metadata.json (143B)\n",
      "Starting upload for file /Users/babak/Documents/model.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10.0G/10.0G [2:54:48<00:00, 956kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: /Users/babak/Documents/model.weights.h5 (9GB)\n",
      "Starting upload for file /Users/babak/Documents/GitHub/desktop-tutorial/README.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 206/206 [00:00<00:00, 256B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: /Users/babak/Documents/GitHub/desktop-tutorial/README.md (206B)\n",
      "Starting upload for file /Users/babak/Documents/.ipynb_checkpoints/Clustering Codealong_Student_Facing_Checkpoint2-checkpoint.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.31M/1.31M [00:02<00:00, 575kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: /Users/babak/Documents/.ipynb_checkpoints/Clustering Codealong_Student_Facing_Checkpoint2-checkpoint.ipynb (1MB)\n",
      "Starting upload for file /Users/babak/Documents/.ipynb_checkpoints/Clustering Codealong_Student_Facing_Checkpoint3-checkpoint.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.92M/1.92M [00:02<00:00, 699kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: /Users/babak/Documents/.ipynb_checkpoints/Clustering Codealong_Student_Facing_Checkpoint3-checkpoint.ipynb (2MB)\n",
      "Starting upload for file /Users/babak/Documents/.ipynb_checkpoints/PCA-checkpoint.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.03M/2.03M [00:03<00:00, 661kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: /Users/babak/Documents/.ipynb_checkpoints/PCA-checkpoint.ipynb (2MB)\n",
      "Starting upload for file /Users/babak/Documents/.ipynb_checkpoints/V4_Clustering Codealong-checkpoint.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.88M/2.88M [00:04<00:00, 712kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: /Users/babak/Documents/.ipynb_checkpoints/V4_Clustering Codealong-checkpoint.ipynb (3MB)\n",
      "Starting upload for file /Users/babak/Documents/.ipynb_checkpoints/Clustering Codealong_Student_Facing_Template-checkpoint.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10.6k/10.6k [00:00<00:00, 14.5kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: /Users/babak/Documents/.ipynb_checkpoints/Clustering Codealong_Student_Facing_Template-checkpoint.ipynb (10KB)\n",
      "Starting upload for file /Users/babak/Documents/assets/tokenizer/vocabulary.spm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.24M/4.24M [00:05<00:00, 812kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: /Users/babak/Documents/assets/tokenizer/vocabulary.spm (4MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n",
      "Your model instance has been created.\n",
      "Files are being processed...\n",
      "See at: https://www.kaggle.com/models/babakdavani/gemmed/keras/finetuned_gpt2\n"
     ]
    }
   ],
   "source": [
    "# Save the finetuned model as a KerasNLP preset.\n",
    "preset_dir = \"/Users/babak/Documents\"\n",
    "gemma_lm.save_to_preset(preset_dir)\n",
    "\n",
    "# Upload the preset as a new model variant on Kaggle\n",
    "kaggle_uri = f\"kaggle://{kaggle_username}/gemmed/keras/finetuned_gpt2\"\n",
    "keras_nlp.upload_preset(kaggle_uri, preset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4b46ab-b23c-4734-822a-6cba26072356",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
